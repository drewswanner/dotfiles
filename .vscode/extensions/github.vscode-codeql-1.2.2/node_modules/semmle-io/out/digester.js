"use strict";
var __await = (this && this.__await) || function (v) { return this instanceof __await ? (this.v = v, this) : new __await(v); }
var __asyncGenerator = (this && this.__asyncGenerator) || function (thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i;
    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }
    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }
    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }
    function fulfill(value) { resume("next", value); }
    function reject(value) { resume("throw", value); }
    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }
};
Object.defineProperty(exports, "__esModule", { value: true });
const leb = require("leb");
function endOfStreamError() {
    return new Error('Attempt to read past end of stream.');
}
const emptyBuffer = Buffer.alloc(0);
/**
 * A class to read and decode bytes out of a sequence of `Buffer`s provided by an async iterator.
 */
class StreamDigester {
    constructor(chunks) {
        this.currentChunk = emptyBuffer;
        this.seamBuffer = emptyBuffer;
        this.done = false;
        this.positionOfCurrentChunk = 0;
        this.offsetInCurrentChunk = 0;
        this.chunks = chunks[Symbol.asyncIterator]();
    }
    /**
     * Create a `StreamDigester`.
     *
     * @param chunks An async iterator that provides the sequence of buffers from which to read.
     */
    static fromChunkIterator(chunks) {
        return new StreamDigester(chunks);
    }
    static fromBuffer(buffer) {
        return new StreamDigester(StreamDigester.singleChunkIterator(buffer));
    }
    get position() {
        return this.positionOfCurrentChunk + this.offsetInCurrentChunk;
    }
    static singleChunkIterator(chunk) {
        return __asyncGenerator(this, arguments, function* singleChunkIterator_1() {
            yield yield __await(chunk);
        });
    }
    /**
     * Gets the next chunk from the iterator, throwing an exception if there are no more chunks
     * available.
     */
    async readNextChunk() {
        if (this.done) {
            throw endOfStreamError();
        }
        const { value, done } = await this.chunks.next();
        if (done) {
            this.done = true;
            throw endOfStreamError();
        }
        this.positionOfCurrentChunk += this.currentChunk.length;
        this.currentChunk = Buffer.from(value);
        this.offsetInCurrentChunk = 0;
    }
    get bytesLeftInCurrentChunk() {
        return this.currentChunk.length - this.offsetInCurrentChunk;
    }
    getSeamBuffer(byteCount, previousBuffer, previousOffset, previousByteCount) {
        if (this.seamBuffer.length < byteCount) {
            // Start at double the current length, or `MIN_SEAM_BUFFER_LENGTH`, whichever is larger.
            let newSeamBufferLength = Math.max(this.seamBuffer.length * 2, StreamDigester.MIN_SEAM_BUFFER_LENGTH);
            while (newSeamBufferLength < byteCount) {
                newSeamBufferLength *= 2;
            }
            this.seamBuffer = Buffer.alloc(newSeamBufferLength);
        }
        if (previousByteCount > 0) {
            if (previousBuffer === this.seamBuffer) {
                if (previousOffset !== 0) {
                    previousBuffer.copyWithin(0, previousOffset, previousOffset + previousByteCount);
                }
            }
            else {
                previousBuffer.copy(this.seamBuffer, 0, previousOffset, previousOffset + previousByteCount);
            }
        }
        return this.seamBuffer;
    }
    async fillBuffer(buffer, start, end) {
        let destOffset = start;
        do {
            const bytesToCopy = Math.min(end - destOffset, this.bytesLeftInCurrentChunk);
            this.currentChunk.copy(buffer, destOffset, this.offsetInCurrentChunk, this.offsetInCurrentChunk + bytesToCopy);
            this.offsetInCurrentChunk += bytesToCopy;
            destOffset += bytesToCopy;
            if (destOffset < end) {
                await this.readNextChunk();
            }
        } while (destOffset < end);
    }
    /**
     * Implements an async read that spans multiple buffers.
     *
     * @param canReadFunc Callback function to determine how many bytes are required to complete the
     *  read operation.
     * @param readFunc Callback function to read the requested data from a `Buffer`.
     */
    async readAcrossSeam(canReadFunc, readFunc) {
        // We'll copy the leftover bytes from the current chunk, plus whatever bytes we need from
        // subsequent chunks, into a "seam buffer", and read the value from there.
        let buffer = this.currentChunk;
        let offsetInBuffer = this.offsetInCurrentChunk;
        let discardedBytes = 0;
        let bytesInBuffer = this.bytesLeftInCurrentChunk;
        while (true) {
            // Ask how many bytes we need to complete the read.
            const requestedBytes = canReadFunc(buffer, offsetInBuffer, bytesInBuffer);
            if (requestedBytes <= bytesInBuffer) {
                // We have enough bytes. Do the read.
                const value = readFunc(buffer, offsetInBuffer);
                this.offsetInCurrentChunk += requestedBytes - discardedBytes;
                return value;
            }
            // We've already copied all the bytes from our current chunk to the seam buffer. We're
            // guaranteed to wind up reading all of those bytes, and will need at least one more byte, so
            // get the next chunk.
            await this.readNextChunk();
            // Create or extend our seam buffer to hold the additional bytes we're about to read.
            const bytesToCopy = Math.min(requestedBytes - bytesInBuffer, this.bytesLeftInCurrentChunk);
            buffer = this.getSeamBuffer(bytesInBuffer + bytesToCopy, buffer, offsetInBuffer, bytesInBuffer);
            discardedBytes = bytesInBuffer;
            offsetInBuffer = 0;
            // Append the new bytes to our seam buffer.
            this.currentChunk.copy(buffer, bytesInBuffer, 0, bytesToCopy);
            bytesInBuffer += bytesToCopy;
        }
    }
    readVariableSize(canReadFunc, readFunc) {
        const requestedBytes = canReadFunc(this.currentChunk, this.offsetInCurrentChunk, this.bytesLeftInCurrentChunk);
        if (requestedBytes <= this.bytesLeftInCurrentChunk) {
            const value = readFunc(this.currentChunk, this.offsetInCurrentChunk);
            this.offsetInCurrentChunk += requestedBytes;
            return Promise.resolve(value);
        }
        else {
            return this.readAcrossSeam(canReadFunc, readFunc);
        }
    }
    readKnownSizeAcrossSeam(byteCount, readFunc) {
        return this.readAcrossSeam((_buffer, _offset, _availableByteCount) => byteCount, readFunc);
    }
    readKnownSize(byteCount, readFunc) {
        if (this.bytesLeftInCurrentChunk >= byteCount) {
            // We have enough data. Just read it directly.
            const value = readFunc(this.currentChunk, this.offsetInCurrentChunk);
            this.offsetInCurrentChunk += byteCount;
            return Promise.resolve(value);
        }
        else {
            return this.readKnownSizeAcrossSeam(byteCount, readFunc);
        }
    }
    /**
     * Read a leb128-encoded unsigned 32-bit number
     * [https://en.wikipedia.org/wiki/LEB128]
     */
    readLEB128UInt32() {
        return this.readVariableSize(canDecodeLEB128UInt32, decodeLEB128UInt32);
    }
    /**
     * Read a single byte.
     */
    readByte() {
        return this.readKnownSize(1, (buffer, offset) => buffer[offset]);
    }
    /**
     * Read a single ASCII character as a string.
     */
    async readASCIIChar() {
        return String.fromCodePoint(await this.readByte());
    }
    /**
     * Read the specified number of bytes.
     *
     * @param byteCount Number of bytes to read.
     */
    async read(byteCount) {
        const buffer = Buffer.alloc(byteCount);
        await this.fillBuffer(buffer, 0, byteCount);
        return buffer;
    }
    /**
     * Read a `Date` encoded as an 8-byte sequence.
     */
    readDate() {
        return this.readKnownSize(8, decodeDate);
    }
    /**
     * Read a little-endian 64-bit IEEE floating-point number.
     */
    readDoubleLE() {
        return this.readKnownSize(8, (buffer, offset) => buffer.readDoubleLE(offset));
    }
    /**
     * Read a UTF-8 encoded string.
     * @param byteCount Length of encoded string in bytes.
     */
    readUTF8String(byteCount) {
        return this.readKnownSize(byteCount, (buffer, offset) => buffer.toString('utf8', offset, offset + byteCount));
    }
}
exports.StreamDigester = StreamDigester;
StreamDigester.MIN_SEAM_BUFFER_LENGTH = 256;
function decodeDate(buffer, offset) {
    const low = buffer.readUInt32LE(offset);
    const high = buffer.readUInt32LE(offset + 4);
    const year = (high & 0x1ffffff0) >> 4;
    const month = high & 0x0000000f;
    const day = (low & 0xf8000000) >>> 27;
    const hours = (low & 0x07c00000) >> 22;
    const minutes = (low & 0x003f0000) >> 16;
    const seconds = (low & 0x0000fc00) >> 10;
    const ms = low & 0x000003ff;
    return new Date(year, month, day, hours, minutes, seconds, ms);
}
/**
 * The longest possible byte length of a correctly encoded LEB128 UInt32:
 * `0xff 0xff 0xff 0xff 0x8f` (5 bytes)
 */
const MAX_ENCODED_UINT32_LENGTH = 5;
function canDecodeLEB128UInt32(buffer, offset, byteCount) {
    const endOffset = offset + Math.min(byteCount, MAX_ENCODED_UINT32_LENGTH);
    for (let byteOffset = offset; byteOffset < endOffset; byteOffset++) {
        if ((buffer[byteOffset] & 0x80) === 0) {
            return (byteOffset - offset) + 1;
        }
    }
    if ((endOffset - offset) > MAX_ENCODED_UINT32_LENGTH) {
        throw new Error('Invalid LEB128 encoding.');
    }
    return MAX_ENCODED_UINT32_LENGTH;
}
function decodeLEB128UInt32(buffer, offset) {
    const { value } = leb.decodeUInt32(buffer, offset);
    return value;
}

//# sourceMappingURL=digester.js.map
